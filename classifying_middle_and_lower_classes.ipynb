{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')\n",
    "\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now if u see in our dataset the label is not 0 and 1 so first we have to convert label into 0 and 1 format. below is the \n",
    "# technique for this work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label == \" <=50K\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here im passing my function \n",
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)\n",
    "\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = census.drop(\"income_bracket\", axis = 1)\n",
    "\n",
    "y_labels = census['income_bracket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_labels, test_size = 0.3, random_state = 101)\n",
    "\n",
    "# now we r gonna create the feature columns, first of all we r going to create columns for the categorical values.\n",
    "# remember vocablist vha use hoti hai jha apko number of options pta hon yani gender me apko pta k sirf male and female hi ho\n",
    "# skty is k elawa or koi nhi. \n",
    "# hash bucket vha use hoti jha apko number of options nhi pta hoty for eg occupation, u dont know how many are there  \n",
    "census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gender = tf.feature_column.cateorical_column_with_vocabulary_list(\"gender\", [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.cateorical_column_with_hash_bucket(\"occupation\", hash_bucket_size = 1000)\n",
    "marital_status = tf.feature_column.cateorical_column_with_hash_bucket(\"marital_status\", hash_bucket_size = 1000)\n",
    "relationship = tf.feature_column.cateorical_column_with_hash_bucket(\"relationship\", hash_bucket_size = 1000)\n",
    "education = tf.feature_column.cateorical_column_with_hash_bucket(\"education\", hash_bucket_size = 1000)\n",
    "workclass = tf.feature_column.cateorical_column_with_hash_bucket(\"workclass\", hash_bucket_size = 1000)\n",
    "native_country = tf.feature_column.cateorical_column_with_hash_bucket(\"native_country\", hash_bucket_size = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now creating the numeric feature columns for the contionus values using numeric_column\n",
    "\n",
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all the features colmn in a single list \n",
    "feat_cols = [gender, occupation, marital_status, relationship, education, workclass, native_country, age, education_num,\n",
    "             capital_gain, capital_loss, hours_per_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets create input for tf.estimator api. note we r using pandas_input_fn blc hmara dataset is vkt pandas dataframe ki form\n",
    "# me moujood hain agr numpy me hota to hum pandas_input_fn nhi use krty\n",
    "\n",
    "input_func = tf.estimtor.inputs.pandas_input_fn(x = x_train, y = y_train, batch_size = 100, num_epochs = None, shuffle = True)\n",
    "\n",
    "# Create the estimator model. Use a linearCLassifier \n",
    "\n",
    "model = tf.estimator.LinearClassifier(feature_columns = feat_cols)\n",
    "\n",
    "model.train(input_fn = input_func, steps = 10000)\n",
    "\n",
    "# note if u use dnn for clasifier then u need to convert categorical column above into embeded categorical column then u need \n",
    "# passs all of these into embedding function \n",
    "# but for linear classifier we dont need to do this thing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn= tf.estimator.inputs.pandas_input_fn(x = x_test, batch_size = len(x_test), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(input_fn = pred_fn)\n",
    "\n",
    "predictions = list(pred_gen)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = [pred[\"class_ids\"][0] for pred in predictions]\n",
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
